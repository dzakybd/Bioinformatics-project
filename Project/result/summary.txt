> We work on hgpca classification
> Process initiated - Building dataset
> Reading COSMIC Cancer Gene Census
> Number of COSMIC Cancer Catalogue: 3946

> Reading CIVIC Cancer Gene Census
> Number of Civic Cancer Catalogue: 366

> Reading Methylation data of TCGA PRAD
> Number of Genes: 20111 | Number of Patients: 549
> Preprocessing Methylation data
> Number of Genes after processing: 821

> not_severe_group.shape (335, 822)
> severe_group.shape (214, 822)
> Saving training and testing data
> Processing completed!
> Applying Logistic Regression
> l1 penalty
> Accuracy = 0.7636363636363637
              precision    recall  f1-score   support

         0.0       0.73      0.98      0.84       101
         1.0       0.93      0.42      0.58        64

   micro avg       0.76      0.76      0.76       165
   macro avg       0.83      0.70      0.71       165
weighted avg       0.81      0.76      0.74       165

> l2 penalty
> Accuracy = 0.7454545454545455
              precision    recall  f1-score   support

         0.0       0.73      0.92      0.82       101
         1.0       0.79      0.47      0.59        64

   micro avg       0.75      0.75      0.75       165
   macro avg       0.76      0.69      0.70       165
weighted avg       0.75      0.75      0.73       165

> Applying KNN
> n=2
> Accuracy = 0.6424242424242425
              precision    recall  f1-score   support

         0.0       0.63      0.98      0.77       101
         1.0       0.78      0.11      0.19        64

   micro avg       0.64      0.64      0.64       165
   macro avg       0.71      0.54      0.48       165
weighted avg       0.69      0.64      0.55       165

> n=3
> Accuracy = 0.6848484848484848
              precision    recall  f1-score   support

         0.0       0.68      0.92      0.78       101
         1.0       0.71      0.31      0.43        64

   micro avg       0.68      0.68      0.68       165
   macro avg       0.70      0.62      0.61       165
weighted avg       0.69      0.68      0.65       165

> n=4
> Accuracy = 0.6606060606060606
              precision    recall  f1-score   support

         0.0       0.65      0.98      0.78       101
         1.0       0.83      0.16      0.26        64

   micro avg       0.66      0.66      0.66       165
   macro avg       0.74      0.57      0.52       165
weighted avg       0.72      0.66      0.58       165

> n=5
> Accuracy = 0.6484848484848484
              precision    recall  f1-score   support

         0.0       0.65      0.90      0.76       101
         1.0       0.62      0.25      0.36        64

   micro avg       0.65      0.65      0.65       165
   macro avg       0.64      0.58      0.56       165
weighted avg       0.64      0.65      0.60       165

> Applying SVM
> linear
> Accuracy = 0.7696969696969697
              precision    recall  f1-score   support

         0.0       0.75      0.93      0.83       101
         1.0       0.82      0.52      0.63        64

   micro avg       0.77      0.77      0.77       165
   macro avg       0.79      0.72      0.73       165
weighted avg       0.78      0.77      0.76       165

> rbf
> Accuracy = 0.6121212121212121
              precision    recall  f1-score   support

         0.0       0.61      1.00      0.76       101
         1.0       0.00      0.00      0.00        64

   micro avg       0.61      0.61      0.61       165
   macro avg       0.31      0.50      0.38       165
weighted avg       0.37      0.61      0.46       165

> poly 2
> Accuracy = 0.6121212121212121
              precision    recall  f1-score   support

         0.0       0.61      1.00      0.76       101
         1.0       0.00      0.00      0.00        64

   micro avg       0.61      0.61      0.61       165
   macro avg       0.31      0.50      0.38       165
weighted avg       0.37      0.61      0.46       165

> poly 3
> Accuracy = 0.6121212121212121
              precision    recall  f1-score   support

         0.0       0.61      1.00      0.76       101
         1.0       0.00      0.00      0.00        64

   micro avg       0.61      0.61      0.61       165
   macro avg       0.31      0.50      0.38       165
weighted avg       0.37      0.61      0.46       165

> poly 4
> Accuracy = 0.6121212121212121
              precision    recall  f1-score   support

         0.0       0.61      1.00      0.76       101
         1.0       0.00      0.00      0.00        64

   micro avg       0.61      0.61      0.61       165
   macro avg       0.31      0.50      0.38       165
weighted avg       0.37      0.61      0.46       165

> Applying MLP
> sigmoid
1 layer
> Accuracy = 0.7212121212121212
              precision    recall  f1-score   support

         0.0       0.71      0.93      0.80       101
         1.0       0.78      0.39      0.52        64

   micro avg       0.72      0.72      0.72       165
   macro avg       0.74      0.66      0.66       165
weighted avg       0.74      0.72      0.69       165

> sigmoid
2 layer
> Accuracy = 0.7515151515151515
              precision    recall  f1-score   support

         0.0       0.73      0.94      0.82       101
         1.0       0.83      0.45      0.59        64

   micro avg       0.75      0.75      0.75       165
   macro avg       0.78      0.70      0.70       165
weighted avg       0.77      0.75      0.73       165

> sigmoid
3 layer
> Accuracy = 0.696969696969697
              precision    recall  f1-score   support

         0.0       0.68      0.95      0.79       101
         1.0       0.79      0.30      0.43        64

   micro avg       0.70      0.70      0.70       165
   macro avg       0.74      0.62      0.61       165
weighted avg       0.72      0.70      0.65       165

> relu
1 layer
> Accuracy = 0.7090909090909091
              precision    recall  f1-score   support

         0.0       0.69      0.96      0.80       101
         1.0       0.83      0.31      0.45        64

   micro avg       0.71      0.71      0.71       165
   macro avg       0.76      0.64      0.63       165
weighted avg       0.74      0.71      0.67       165

> relu
2 layer
> Accuracy = 0.7333333333333333
              precision    recall  f1-score   support

         0.0       0.74      0.87      0.80       101
         1.0       0.72      0.52      0.60        64

   micro avg       0.73      0.73      0.73       165
   macro avg       0.73      0.69      0.70       165
weighted avg       0.73      0.73      0.72       165

> relu
3 layer
> Accuracy = 0.7515151515151515
              precision    recall  f1-score   support

         0.0       0.80      0.79      0.80       101
         1.0       0.68      0.69      0.68        64

   micro avg       0.75      0.75      0.75       165
   macro avg       0.74      0.74      0.74       165
weighted avg       0.75      0.75      0.75       165

